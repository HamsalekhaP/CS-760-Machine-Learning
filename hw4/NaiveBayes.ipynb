{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import operator\n",
    "%matplotlib  inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data as per problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=[0, 10]\n",
    "test_set =[11,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self,unique_classes, expSet):\n",
    "        self.globVocab = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z', ' ']\n",
    "        self.classes=unique_classes\n",
    "        self.clasDict={}\n",
    "        self.clasVocabulary={}\n",
    "        self.bagOfChar={}\n",
    "        self.expSet=expSet\n",
    "        self.classConditonalProbData={}\n",
    "        self.bagOfCharsCountsVector={}\n",
    "        self.conditonalProb={}\n",
    "        self.conditionalProbabilities={}\n",
    "    \n",
    "    \n",
    "    def getClassCharacters(self):\n",
    "        for clas in self.classes:\n",
    "            self.clasDict[clas]=[]\n",
    "            x=[]\n",
    "            for i in range(self.expSet[0],self.expSet[1]):\n",
    "                filepath= clas + str(i) + '.txt'\n",
    "                with open(filepath) as f:\n",
    "                    x.extend([char for char in f.read().replace(\"\\n\", \"\")])\n",
    "            # has all the characters belonging to each class as a list in sorted order\n",
    "            self.clasDict[clas]=sorted(x)\n",
    "     \n",
    "    def getFreqOfChar(self, data):\n",
    "            vocab={el:0 for el in self.globVocab}\n",
    "            for char in data:\n",
    "                if char in vocab:\n",
    "                    vocab[char]+=1\n",
    "                else:\n",
    "                    vocab[char]= 1\n",
    "            # create a frequency vocabulary. \n",
    "            # Has number of times each character from the set of all vocabulary appears in the respetive class\n",
    "            return vocab\n",
    "        \n",
    "    def createClasVocaAndProbCounts(self):\n",
    "        for clas in self.classes:\n",
    "            sortedDictSet=sorted(set(self.clasDict[clas]))\n",
    "            sortedDictSet.pop(0)\n",
    "            sortedDictSet.extend([' '])\n",
    "            # has the set of vocabulary ie ., a list of all unique characters\n",
    "            self.clasVocabulary[clas]= sortedDictSet\n",
    "            ##### check for additonal element count for add 1 smoothing\n",
    "            self.bagOfChar[clas] = self.getFreqOfChar(self.clasDict[clas])\n",
    "    \n",
    "    def findClassCondProb(self):\n",
    "        for clas in self.classes:\n",
    "            den = len(self.clasDict[clas]) + len(self.clasVocabulary[clas]) \n",
    "            #print(len(self.clasDict[clas]),len(self.clasVocabulary[clas]))\n",
    "            theta=[]\n",
    "            for key, value in self.bagOfChar[clas].items():\n",
    "                theta.extend([int(value)])\n",
    "            #just vector of frequencies of char occurences in each class\n",
    "            self.bagOfCharsCountsVector[clas]= theta\n",
    "            #class conditional probabilities from train data\n",
    "            self.classConditonalProbData[clas]=(1 + np.array(theta))/den\n",
    "     \n",
    "    def multinomialClassCondProb(self, testData):       \n",
    "        for clas in self.classes:\n",
    "            s = self.classConditonalProbData[clas]\n",
    "            f = np.array(testData)\n",
    "            #f = np.array(self.bagOfCharsCountsVector[clas])\n",
    "            self.conditonalProb[clas] = np.dot(f, np.log(s))\n",
    "            self.conditionalProbabilities[clas]= math.exp(self.conditonalProb[clas])\n",
    "        print('conditonalProb exp power',self.conditonalProb)\n",
    "        ##very high power to be dectected as any value\n",
    "        #print('conditionalProbabilities',self.conditionalProbabilities)\n",
    "        \n",
    "    def totalProb(self):\n",
    "        probOfX = max(self.conditonalProb.items(), key=operator.itemgetter(1))[0]\n",
    "        for clas in self.classes:\n",
    "            por = self.conditonalProb[clas] - self.conditonalProb[probOfX]\n",
    "            print(por)\n",
    "            print('posterior',math.exp(por))\n",
    "    \n",
    "    def bayesClassify(self):\n",
    "        posteriorProb={}\n",
    "        for clas in self.classes:\n",
    "            posteriorProb[clas]= self.conditonalProb[clas]\n",
    "            #posteriorProb[clas]= (1/3) * self.conditionalProbabilities[clas]\n",
    "        maxProb=max(posteriorProb.items(), key=operator.itemgetter(1))[0]\n",
    "        self.totalProb()\n",
    "        return(max(posteriorProb.items(), key=operator.itemgetter(1))[0])\n",
    "            \n",
    "    def fetchFileData(self,fileName):\n",
    "        x=[]\n",
    "        filepath= fileName\n",
    "        with open(filepath) as f:\n",
    "            x.extend([char for char in f.read().replace(\"\\n\", \"\")])\n",
    "        return x\n",
    "\n",
    "    def train(self):\n",
    "        self.getClassCharacters()\n",
    "        self.createClasVocaAndProbCounts()\n",
    "        self.findClassCondProb()\n",
    "    \n",
    "    def test(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Bayes Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_list =['e','j','s']\n",
    "train_set=[0, 10]\n",
    "test_set =[10,20]\n",
    "\n",
    "cls=NaiveBayes(class_list, train_set)\n",
    "cls.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 164, 'b': 32, 'c': 53, 'd': 57, 'e': 311, 'f': 55, 'g': 51, 'h': 140, 'i': 140, 'j': 3, 'k': 6, 'l': 85, 'm': 64, 'n': 139, 'o': 182, 'p': 53, 'q': 3, 'r': 141, 's': 186, 't': 225, 'u': 65, 'v': 31, 'w': 47, 'x': 4, 'y': 38, 'z': 2, ' ': 498}\n",
      "conditonalProb exp power {'e': -7841.78638677036, 'j': -8759.325135216695, 's': -8452.383194656028}\n",
      "maxden -7841.78638677036\n",
      "0.0\n",
      "posterior 1.0\n",
      "-917.5387484463354\n",
      "posterior 0.0\n",
      "-610.5968078856677\n",
      "posterior 6.62484417438748e-266\n",
      "predicted class e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testfreqDict = cls.getFreqOfChar(sorted(cls.fetchFileData('e10.txt')))\n",
    "print(testfreqDict)\n",
    "theta=[]\n",
    "for key, value in testfreqDict.items():\n",
    "    theta.extend([int(value)])\n",
    "cls.multinomialClassCondProb(theta)\n",
    "testPrediction=cls.bayesClassify()\n",
    "print('predicted class',testPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groundTruth=[]\n",
    "pred=[]\n",
    "for clas in class_list:\n",
    "    for inde in range(test_set[0],test_set[1]):\n",
    "        filepath = clas + str(inde) + '.txt'\n",
    "        groundTruth.extend(clas)\n",
    "        testfreqDict = cls.getFreqOfChar(sorted(cls.fetchFileData(filepath)))\n",
    "        theta=[]\n",
    "        for key, value in testfreqDict.items():\n",
    "            theta.extend([int(value)])\n",
    "        cls.multinomialClassCondProb(theta)\n",
    "        pred.extend(cls.bayesClassify())\n",
    "print('ground truth classification for 10  test documents',groundTruth)\n",
    "print('Predicted classification for 10  test documents',pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(groundTruth,pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "xy=[]\n",
    "with open('e10.txt') as f:\n",
    "    xy.extend([char for char in f.read().replace(\"\\n\", \"\")])\n",
    "#print(xy)\n",
    "random.shuffle(xy)\n",
    "print(xy)\n",
    "\n",
    "testfreqDict = cls.getFreqOfChar(sorted(xy))\n",
    "#print(testfreqDict)\n",
    "theta=[]\n",
    "for key, value in testfreqDict.items():\n",
    "    theta.extend([int(value)])\n",
    "    \n",
    "print(theta)\n",
    "cls.multinomialClassCondProb(theta)\n",
    "testPrediction=cls.bayesClassify()\n",
    "print('predicted class',testPrediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate modified files for Weka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clas in ['e','j','s']:            \n",
    "    for j in range(20):\n",
    "        filepath= clas + str(j) + '.txt'\n",
    "        with open(filepath) as f:\n",
    "            textList = list(f.read().replace(\"\\n\", \"\"))\n",
    "            for i in range(0, len(textList)):\n",
    "                if textList[i] == \" \":\n",
    "                    textList[i] = \"space\"\n",
    "            text = ' '.join(textList)\n",
    "        writeToFile= clas + str(j) + 'updated.txt'\n",
    "        with open(writeToFile, \"w\") as text_file:\n",
    "            text_file.write(text)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
